%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Thin Sectioned Essay
% LaTeX Template
% Version 1.0 (3/8/13)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original Author:
% Nicolas Diaz (nsdiaz@uc.cl) with extensive modifications by:
% Vel (vel@latextemplates.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%   PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[a4paper,11pt]{article}

\usepackage{draftwatermark}
\SetWatermarkText{draft}
% \SetWatermarkScale{5}
\SetWatermarkColor[gray]{0.87}


\usepackage[utf8]{inputenc}
\usepackage[protrusion=true,expansion=true]{microtype} % Better typography
\usepackage{graphicx} % Required for including pictures
\usepackage{wrapfig} % Allows in-line images
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage[tikz]{bclogo}
\usepackage{minted}
\usepackage{subcaption}
% \setsansfont{Calibri}
% \setmonofont{Consolas}



\usepackage{mathpazo} % Use the Palatino font
\usepackage[T1]{fontenc} % Required for accented characters
\linespread{1.05} % Change line spacing here, Palatino benefits from a slight increase by default

\makeatletter
\renewcommand\@biblabel[1]{\textbf{#1.}} % Change the square brackets for each bibliography item from '[1]' to '1.'
\renewcommand{\@listI}{\itemsep=0pt} % Reduce the space between items in the itemize and enumerate environments and the bibliography

\renewcommand{\maketitle}{ % Customize the title - do not edit title and author name here, see the TITLE block below
\begin{flushright} % Right align
{\LARGE\@title} % Increase the font size of the title

\vspace{50pt} % Some vertical space between the title and author name

{\large\@author} % Author name
\\\@date % Date

\vspace{40pt} % Some vertical space between the author block and abstract
\end{flushright}
}


% \makeatletter
\newenvironment{fancyquote}[2][2em]
  {\setlength{\@tempdima}{#1}%
   \def\chapquote@author{#2}%
   \parshape 1 \@tempdima \dimexpr\textwidth-2\@tempdima\relax%
   \itshape}
  {\par\normalfont\hfill--\ \chapquote@author\hspace*{\@tempdima}\par\bigskip}
\makeatother


%----------------------------------------------------------------------------------------
%   TITLE
%----------------------------------------------------------------------------------------

\title{\textbf{Data don't speak for themselves}\\ % Title
a Bayesian course} % Subtitle

\author{\textsc{João P. Faria} % Author
\\{\textit{Institute of Astrophysics and Space Sciences, Porto}}} % Institution

\date{\today} % Date

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle % Print the title section

%----------------------------------------------------------------------------------------
%   ABSTRACT AND KEYWORDS
%----------------------------------------------------------------------------------------

%\renewcommand{\abstractname}{Summary} % Uncomment to change the name of the abstract to something else

\begin{abstract}
Bayesian statistics is rising in popularity in the astrophysical literature. 
It is no longer a debate: ``work in Bayesian statistics now focuses on applications, computations, and models. Philosophical debates [...] are fading to the background'' \cite{Gelman2014}. 
This is happening for two main reasons: faster computers and more complex models. 
In order to keep up, it is important to understand the fundamentals of Bayesian statistics, but it is as important to know how to deal with data analysis applications. 
In this course I want to provide a brief introduction to advanced concepts in Bayesian statistics.
Emphasis will be on \emph{intuition} and \emph{computation}.
No coin tossing, only real applications that relate to our day-to-day problems. 
\end{abstract}

% \hspace*{3,6mm}\textit{Keywords:} lorem , ipsum , dolor , sit amet , lectus % Keywords

\vspace{30pt} % Some vertical space between the abstract and first section

\tableofcontents


\newpage
\begin{center}
  \section*{Before you read}
  
  This document is not finished! \\
  What I have written here is not completely original work: I follow closely, and base the discussion on, many different sources. 
  Because it's not finished, I have not yet made fair attribution to all these sources.\\[0.2in]
  I mean no infringement of copyright and no plagiarism.
\end{center}





%----------------------------------------------------------------------------------------
%   ESSAY BODY
%----------------------------------------------------------------------------------------

\newpage
\section*{A (tiny) primer on philosophy}
\addcontentsline{toc}{section}{A (tiny) primer on philosophy}

While preparing for this course, I asked people what it was they wanted to learn about.
Much to my dismay, no one answered with ``the philosophy of Bayesian statistics''.
Most want to learn about the ``theory'' and ``applications'' (read MCMC).
They want to know how they can \emph{use} Bayesian statistics in their work%
\footnote{I later read \cite{Loredo1994} and realised this is not the case for our institute only.}.

Fair enough. But bypassing phylosophy means making assumptions.
Therefore, I shall introduce here Jaynes' \emph{robot}, an imaginary being whose brain reasons according to certain definite rules \cite{Jaynes2003}.
These rules will simply be stated, not derived and not defended (Sect. \ref{sec:basics}). 
They will be taken as being true. 
Then, everything that follows logically from them, everything the robot does, will be true.

In the words of \cite{Loredo1994}, these rules make Bayesian inference ``more like integration'' in that it provides a ``collection of tools for finding definitive answers to well-posed problems''. 
Posing the problem will require subjective knowledge; solving it will not.


\section{The basics of probability theory}\label{sec:basics}

Here we present the rules of the game, following very closely (too closely!) the presentation in \cite{Hogg2012}.
Using Bayesian statistics to analyse data (some might call it doing probabilistic inference) means working with likelihoods, prior probabilities, posterior probabilities and marginalization of nuisance parameters.
All this will be explained later but the options we have when working with these mathematical objects are strongly constrained by the rules of probability calculus.

\vskip1em
\begin{fancyquote}{Pierre-Simon Laplace}
   On voit, par cet Essai, que la théorie des probabilités n'est, au fond, que le bon sens réduit au calcul;
\end{fancyquote}

If we have a continuous parameter $a$, and a probability distribution function $p(a)$ for%
\footnote{I say \emph{for} instead of \emph{of}, but I promised no philosophy...} $a$, it must obey the normalization condition
%
\begin{equation}
   1 = \int p(a) \, da
\end{equation}
%
where the integral is limited by the domain%
% \footnote{The domain of $a$ is called the \emph{support} of $p(a)$.}%
~of $a$.

Often times we will have more than one parameter. 
Even if we \emph{condition} $p(a)$ on some particular value of another parameter $b$, that is, we ask for $p(a | b)$ (read ``the pdf for $a$ given $b$''), it must obey the same normalization
%
\begin{equation}\label{eq:normalisation}
   1 = \int p(a|b) \, da
\end{equation}
%

If we have a probability distribution for two things, $p(a,b)$ (read ``the pdf for $a$ and
$b$''), you can always factorize it into two distributions, one for $a$, and one for $b$ given $a$ or the other way around:
%
\begin{align}
   p(a,b) &= p(a) \, p(b|a)\\
   p(a,b) &= p(b) \, p(a|b)
\end{align}
%

These two factorisations together lead%
\footnote{Bayes' theorem is a consequence of the previous equations, it is not assumed as a rule. That's why it's called a theorem, actually.} to Bayes' theorem:
%
\begin{equation}
   p(a|b) = \frac{p(b|a)\,p(a)}{p(b)} .
\end{equation}
%

Conditional probabilities factor just the same as unconditional ones
%
\begin{align}
   p(a,b|c) &= p(a|c) \, p(b|a,c)\\
   p(a,b|c) &= p(b|c) \, p(a|b,c)\\
   p(a|b,c) &= \frac{p(b|a,c)\,p(a|c)}{p(b|c)} \label{eq:bayes}
\end{align}
%   
where we just carried the condition $c$ through all the terms.

You can integrate out or \emph{marginalize} variables you want to get rid of (or \emph{not} infer) by integrals like
%
\begin{align}
   p(a|c) &= \int p(a,b|c) \, db \\
   p(a|c) &= \int p(a|b,c)\,p(b|c) \, db
\end{align}
%
where the second is a factorized version of the first.
Remember that, since $b$ can be a very high-dimensional mathematical object (a set of parameters), integrals like these can be extremely difficult to calculate in practice.


\subsection{Some familiarity}

Let us write some of the preceding equations with more familiar terms%
\footnote{Only if you have heard about Bayesian statistics, otherwise just different terms.}.

\noindent We have data $D$ and a set of parameters $\theta$ that we are interested in learning about. 
In all our analyses we condition on information $\mathcal{I}$ that we have about the world.
Then we can write Eq. \eqref{eq:bayes} as
%
\begin{equation}\label{eq:bayes2}
  p(\theta|D,\mathcal{I}) = \frac{p(\theta|\mathcal{I}) \, p(D|\theta,\mathcal{I})}{p(D|\mathcal{I})}
\end{equation}

The terms in this equation are usually called
%
\begin{itemize}
   \item[] $p(\theta|D,\mathcal{I})$ the posterior distribution
   \item[] $p(\theta|\mathcal{I})$ the prior distribution
   \item[] $p(D|\theta,\mathcal{I})$ the likelihood
   \item[] $p(D|\mathcal{I})$ the evidence, sometimes denoted with a $\mathcal{Z}$.
\end{itemize}
%
but calling them this may hide something important (see Section \ref{sec:likelihood}).

From Eq. \eqref{eq:normalisation} we can derive%
\footnote{Multiply both sides of Eq. \eqref{eq:bayes} by $p(D|\mathcal{I})$ and integrate over $\theta$, noting that $p(D|\mathcal{I})$ does not depend on $\theta$ and that the posterior obeys Eq. \eqref{eq:normalisation}.}
that
%
\begin{equation}
   p(D|\mathcal{I}) = \mathcal{Z} = \int p(\theta|\mathcal{I}) \, p(D|\theta,\mathcal{I}) \, d\theta
\end{equation}
%

Because $\mathcal{Z}$ does not depend on $\theta$, you might see many times Eq. \eqref{eq:bayes2} written as
%
\begin{equation}\label{eq:propto}
   p(\theta|D,\mathcal{I}) \propto p(\theta|\mathcal{I}) \, p(D|\theta,\mathcal{I}) ,
\end{equation}
%
so \textbf{the posterior is proportional to the likelihood times the prior}.
Nevertheless, try to stick with Eq. \eqref{eq:bayes2}; $\mathcal{Z}$ contains in it a big deal of information.

\vskip1em
\begin{bclogo}[logo=\bclampe, couleur=blue!15, couleurBord=black ,couleurBarre=blue!15]{ think about it}
   Eq. \eqref{eq:propto} means that the likelihood and the prior can be defined up to an arbitrary multiplicative constant (i.e. not a function of $\theta$).
\end{bclogo}


For example, imagine we are interested in comparing two models $M_1$ and $M_2$ which have parameters $\theta_1$ and $\theta_2$, respectively. We still only have data $D$. Bayes' theorem works the same:
%
\begin{equation}
   p(M_i|D,\mathcal{I}) = \frac{p(M_i|\mathcal{I}) \, p(D|M_i,\mathcal{I})}{p(D|\mathcal{I})}
\end{equation}
%
and the ratio of model probabilities is
%
\begin{align}
 \frac{p(M_1|D,\mathcal{I})}{p(M_2|D,\mathcal{I})}
   &= \frac{p(M_1|\mathcal{I}) \, p(D|M_1,\mathcal{I})}{p(M_2|\mathcal{I}) \, p(D|M_2,\mathcal{I})} \\[0.4em]
   &= \frac{p(M_1|\mathcal{I}) \, \int p(D,\theta_1|M_1,\mathcal{I})\,d\theta_1}
           {p(M_2|\mathcal{I}) \, \int p(D,\theta_2|M_2,\mathcal{I})\,d\theta_2} \\[0.4em]
   &= \frac{p(M_1|\mathcal{I}) \, \int p(\theta_1|M_1, \mathcal{I}) \, p(D|\theta_1,M_1,\mathcal{I}) \, d\theta_1}
           {p(M_2|\mathcal{I}) \, \int p(\theta_2|M_2, \mathcal{I}) \, p(D|\theta_2,M_2,\mathcal{I}) \, d\theta_2}
           \label{eq:model_comp3} \quad.
\end{align}
%
See how the evidence (of both models) turns out to be important! 

\noindent The term
%
\[\frac{p(M_1|\mathcal{I})}{p(M_2|\mathcal{I})}\]
%
is the ratio of prior probabilities for the two models. 
If we believe they are equally likely at the start, then this is equal to 1.

\vskip1em
\begin{bclogo}[logo=\bclampe, couleur=blue!15, couleurBord=black ,couleurBarre=blue!15]{ think about it}
   $\theta_1$ and $\theta_2$ can be any set of parameters and, in particular, they can have different sizes.
   Say model $M_1$ has 2 parameters $\theta_1 = (a, b)$ and model $M_2$ only has one parameter $\theta_2 = (c)$.
   Then the integrals in Eq. \eqref{eq:model_comp3} are of different dimensionality.
   That's fine, probability theory doesn't care.
   Enough of that ``divide by the degrees of freedom'' nonsense! \cite{Andrae2010}
\end{bclogo}


\section{Assigning probabilities}

Now that we have a set of rules with which we can manipulate our distributions, it is useful to learn how we can assign values to all these terms and actually start calculating things.

\subsection{The prior}\label{sec:prior}

The dreadful prior, we wish we didn't have to deal with it. 
But having to specify priors is a good excuse to learn about different probability distributions. 
See Fig. \ref{fig:distributions}, which shows the general form of many continuous probability distributions.

We can start with the Normal distribution.
A variable $x$ is normally distributed if its pdf is

\begin{equation}
  \text{pdf}(x|\mu, \sigma) = \frac{1}{\sigma \sqrt{2\pi}} 
                              \exp\left[-\frac{(x-\mu)^2}{2\sigma^2}\right]
\end{equation}

where $\mu$ and $\sigma$ are the two parameters of the Normal distribution.
We will use the following notation to say that $x$ follows a Normal distribution:
%
\[x \sim \mathcal{N}(\mu, \sigma)\]
%

The Normal distribution is defined on the real line, so $x$ can take any value between $-\infty$ and $\infty$.
The parameter $\mu$ is the mean of the distribution and $\sigma$ is the standard deviation.
Values of $x$ closer to $\mu$ are more probable that those far from $\mu$.


The uniform distribution is also quite common
%
\begin{equation}
x \sim \mathcal{U}(a, b) \quad \text{if} \quad \text{pdf}(x|a,b) = \frac{1}{a-b}
\end{equation}
%

For the uniform distribution, all values between $a$ and $b$ are equally probable.
The probability that $x<a$ is 0 and the same for $x>b$. These values of $x$ are \emph{impossible}.


Another distribution which might come in handy is the reciprocal distribution (it is not shown in Fig. \ref{fig:distributions}):
%
\begin{equation}\label{eq:reciprocal}
x \sim \mathcal{R}(a, b) \quad \text{if} \quad \text{pdf}(x|a,b) = \frac{1}{x\left[\log(b) - \log(a) \right]}
\end{equation}
%
where $a$ and $b$ are the lower and upper bounds of the support (note that $\log$ is the natural logarithm, sometimes denoted as $\ln$).


Let us introduce briefly one more distribution, the \emph{t}-distribution:
%
\begin{equation}
  x \sim t(\nu,\mu,\sigma) \quad \text{if} \quad \text{pdf}(x|\nu, \mu, \sigma) = 
            \frac{\Gamma(\frac{\nu+1}{2})}{\Gamma(\frac{\nu}{2})\sqrt{\pi\nu}\,\sigma}
            \left[ 1 + \frac{1}{\nu} \left(\frac{x-\mu}{\sigma}\right)^2 \right]
                  ^{-\frac{\nu+1}{2}}
\label{eq:tdistribution}
\end{equation}
%
with the degrees of freedom $\nu$, the mean $\mu$ and the scale $\sigma$ as parameters.
In Eq. \eqref{eq:tdistribution}, $\Gamma$ is the gamma function.

This distribution looks complicated but I mention it here for one reason: note how in Fig. \ref{fig:distributions}, the normal and \emph{t} distributions look very similar, they are both bell-shaped.
The distinguishing feature is that the \emph{t}-distribution has \emph{heavier tails}, that is, values of $x$ far from the mean are more probable if $x$ is \emph{t} distributed than if $x$ if normally distributed.
How heavy the tails are depends on the parameter $\nu$.
For example, imagine that
%
\begin{align}
  x_1 & \sim \mathcal{N}(0, 1) \\
  x_2 & \sim t(2, 0, 1)
\end{align}
%
and you obtain 100\,000 random samples from these two distributions. 
Then you calculate the minimum value of all the samples for $x_1$ and all the samples for $x_2$.
Will these values be very different?
%
\begin{minted}[linenos,
               numbersep=7pt,
               gobble=2,
               frame=lines,
               framesep=0mm]{python}
  from scipy.stats import norm, t
  
  print min( t(1., loc=0, scale=1).rvs(100000) )
  print min( norm(loc=0, scale=1).rvs(100000) )
\end{minted}

They are completely different! By orders of magnitude!

\noindent The \emph{t}-distribution allows for more extreme values.
This will come in handy when we deal with outliers.

\vskip1em
Other distributions have different pdfs and different parameters. 
Wikipedia usually has a lot of information about the most common ones, just search for the names you see in Fig. \ref{fig:distributions}. 

\begin{figure}[h]
  \centering
  \includegraphics[width=0.7\linewidth]{../figs/distributions.png}
  \caption{Continuous probability distributions. Adapted from \href{http://semanticommunity.info/Data_Science/Doing_Data_Science\#Slide_1_Hubway_Data_Visualization_Challenge:_Spotfire}{here}.}
  \label{fig:distributions}
\end{figure}


The key concept about priors is to use (some of) these probability distributions to describe our beliefs about the parameters in our models.

\begin{itemize}
  \item if any value of the parameter seems equally likely but you have an idea of its order of magnitude, try a uniform distribution in a sensible range.
  \item if one value is somewhat more likely and, again, you know the order of magnitude, try a normal distribution centred in that value.
  \item if any value is equally likely within a few orders of magnitude, use a log-normal or an exponential distribution. [check!!!]
  \item if the parameter takes values between 0 and 1, the beta distribution is defined in this interval and can take a wide range of forms, depending on its parameters.
\end{itemize}

Every time you come up with a prior, you are using your expert knowledge about the problem.
Don't underestimate this knowledge by trying to set an ``uninformative'' prior at all costs.
If you are not sure, try a few different priors and see if the results make sense and are consistent.
If you reach different conclusions by changing the priors, mention this when you write your paper.

The only way in which you can go completely wrong and change the results dramatically is by setting the prior to 0. 
No amount of data can change a prior which is zero.


\vskip1em
\begin{bclogo}[logo=\bclampe, couleur=blue!15, couleurBord=black ,couleurBarre=blue!15]{ think about it}
   If the prior distribution is 0, the posterior distribution is 0, independent of the likelihood.
   This reflects a very strong assumption.
\end{bclogo}

% Finally, if a result is not robust to reasonable changes in the problem specification, this itself should be recognized as important information.  If the answer depends sensitively on something we do not know, then we do not know the answer


\subsubsection{An example} % (fold)
\label{ssub:an_example}

  Let's try to write a \texttt{Python} code to calculate the prior in a simple example.

  First, we state some of the information that is included in $\mathcal{I}$.
  The radial-velocity signal induced in a star by an orbiting planet depends

  \begin{itemize}
    \item on the orbital period, $P$
    \item on the semi-amplitude, $K$
    \item on the eccentricity, $e$
    \item on the argument of periastron, $\omega$
    \item on the phase of periastron, $\chi$
  \end{itemize}

  and we know both the units and the appropriate ranges for most of these parameters.
  For some parameters, like the orbital period and semi-amplitude, we may not be completely sure about the allowed ranges, 
  but we can still make some informed guesses based on our knowledge of physics and astronomy.

  What about the mathematical forms of the priors. Well, we can start by dividing the parameters into two classes: location and scale parameters.
  The semi-amplitude is clearly a scale parameter as it does not matter if we measure it in $m\,s^{-1}$, $km\,s^{-1}$, or any other velocity unit. 
  If we want our prior to be \emph{scale-invariant}, then an appropriate distribution to use is the reciprocal distribution of Eq. \eqref{eq:reciprocal}.
  The same can be said for the orbital period, which can be measured in days, seconds, months, etc.

  The argument of periastron and phase of periastron are angles that place the planet's orbit in the three-dimensional space.
  Angles can be measured with respect to an arbitrary direction, so these are location parameters. 
  We don't care if our parameter is defined as $\omega$ or as $\omega'=\omega+\pi$.
  An appropriate prior here is the uniform prior. 

  It's harder to justify that the eccentricity is also a location parameter.
  But in any case we know that, for an elliptical orbit, it should take values between 0 and 1.
  If we don't know much more (though sometimes we do, see \cite{Kipping2013}) we can go with a uniform prior for $e$ as well.

  So, in summary:

  \begin{itemize}
    \item[] orbital period         \hfill $p(P|\mathcal{I}) \sim \mathcal{J}(1, 1000)$ days
    \item[] semi-amplitude         \hfill $p(K|\mathcal{I}) \sim \mathcal{J}(0.1, 100)$ ms$^{-1}$
    \item[] eccentricity           \hfill $p(e|\mathcal{I}) \sim \mathcal{U}(0, 1)$
    \item[] argument of periastron \hfill $p(\omega|\mathcal{I}) \sim \mathcal{U}(0, 2\pi)$
    \item[] phase of periastron    \hfill $p(\chi|\mathcal{I}) \sim \mathcal{U}(0, 2\pi)$
  \end{itemize}
  %
  and we can further assume that these parameters are independent, so their joint prior distribution
  is the product of the individual priors
  %
  \begin{equation}
    p(P,K,e,\omega,\chi|\mathcal{I}) = p(P|\mathcal{I}) \, p(K|\mathcal{I}) \, p(e|\mathcal{I}) \, p(\omega|\mathcal{I}) \, p(\chi|\mathcal{I})
  \end{equation}

  Let's write this in \texttt{Python}, using the distributions from \texttt{Scipy}.
  We want a function \texttt{prior(P,K,e,w,X)} that returns the value of the prior pdf, given values of the parameters.

  %
  \begin{minted}[linenos,
                 numbersep=7pt,
                 gobble=2,
                 frame=lines,
                 framesep=0mm]{python}
    from scipy.stats import *
    from numpy import product

    def prior(P,K,e,w,X):
      prior_P = reciprocal(a=1,b=1000).pdf(P)
      prior_K = reciprocal(a=0.1,b=100).pdf(K)
      prior_e = uniform().pdf(e)
      prior_w = uniform(scale=2*pi).pdf(w)
      prior_X = uniform(scale=2*pi).pdf(X)

      return product([prior_P, prior_K, prior_e, prior_w, prior_X])
  \end{minted}


  This will work in most cases, but we are in danger of underflowing: multiplying small numbers can lead to \emph{very} small numbers.
  So it might be better to work with logarithms:
  %
  \begin{minted}[linenos,
                 numbersep=7pt,
                 gobble=2,
                 frame=lines,
                 framesep=0mm]{python}
    from scipy.stats import *
    from numpy import sum

    def log_prior(P,K,e,w,X):
      log_prior_P = reciprocal(a=1,b=1000).logpdf(P)
      log_prior_K = reciprocal(a=0.1,b=100).logpdf(K)
      log_prior_e = uniform().logpdf(e)
      log_prior_w = uniform(scale=2*pi).logpdf(w)
      log_prior_X = uniform(scale=2*pi).logpdf(X)

      return sum([prior_P, prior_K, prior_e, prior_w, prior_X])
  \end{minted}

  \textbf{Note:} the functions defined above are probably not the most efficient way to calculate the prior. 
  But they are certainly very readable!
  If ``future-you'' will understand the code ``present-you'' wrote, that's a good thing!



% subsubsection an_example (end)


\subsection{The likelihood}\label{sec:likelihood}

The likelihood is a prior.
I will repeat so you know this is not a typo: the likelihood is a prior.
The term $p(D|\theta,I)$ represents your beliefs on what the data will be like, given parameters $\theta$ and information $I$.
Therefore, the likelihood encodes prior information.
%
Following \cite{Brewer2013}, the likelihood is \emph{not} 
\begin{itemize}
   \item[-] the process that generated the data
   \item[-] the pdf that your data kind of looks like when you plot it in a histogram
\end{itemize}

It is, instead, what we usually call \emph{the model}.
And the model is nothing else than a set of assumptions about the data and how they relate to the parameters.
\textbf{The likelihood provides a (\emph{the}) connection from $\theta$ to $D$}.

But now comes the part which, conceptually, is harder to understand. 
When we write $p(D|\theta,I)$, this is a distribution for the data, given some values for the parameters $\theta$.
A ``point'' taken randomly from $p(D|\theta,I)$, corresponds to a random dataset.
But the likelihood is sometimes seen instead as a function of the parameters, given the observed dataset. 
In this form, the symbol $\mathcal{L}(\theta)$ is often used.

\begin{itemize}
  \item $p(D|\theta,I)$ - distribution for datasets, given value of $\theta$
  \item $\mathcal{L}(\theta)$ - function of $\theta$
\end{itemize}

This used to confuse me. 
If it confuses you too, maybe an example will help.
Consider Fig. \ref{fig:2nd_degree_like}, which tries to illustrate the likelihood.

We are considering a model of the form $f(x) = A_1 + A_2\,x + A_3\, x^2$ and a Gaussian likelihood.
The model prediction for a specific value of the parameters ($A_1 = 0.5; A_2 = 0.8; A_3 = -0.06$)
is shown in blue. 
The data we have actually observed are 5 pairs of values $(x_i, y_i)$, marked by the red crosses.
On the \emph{z}-axis we depict the Gaussian likelihood distributions.
These are Gaussian functions centered at each $f(x_i)$.
We assumed that the width of these Gaussians is the same for all, and equal to $\sigma$.

You can see that, for the assumed choice of model parameters, the probability of any $d_i$ is
proportional to the height of the Gaussian curve directly above that data point, as shown by the solid lines.
The probability of the complete dataset, $\{d_i\}_{i=1}^5$, is the product of the individual probabilities.

If our data comes with error-bars, that is we have $(x_i, y_i, \sigma_i)$, and we want to incorporate that
in the likelihood, then things are more like in Fig. \ref{fig:2nd_degree_like_heteroskedastic}.
Now each Gaussian has a different width and the data is depicted with an errorbar on the \emph{y} direction.


\begin{figure}
  \centering
  \includegraphics[width=0.8\linewidth]{../figs/likelihood_9.pdf}
  \caption{Illustration of the calculation of the likelihood function for a model of the form $f(x) = A_1 + A_2\,x + A_3\, x^2$.
           The smooth blue curve is the model prediction for a specific choice of the parameters. 
           The predicted values of $f(x_i)$ for each choice of the independent variable $x_i$ are marked by a dashed line.
           The actual measured value of $d_i$ (represented by a red cross) is located at the same value of $x_i$ but above or below $f(x_i)$ as a result of the uncertainty $\sigma$.
           At the location of each $f(x_i)$ value we have constructed a Gaussian probability density function, with probability plotted in the z-coordinate. 
           For the assumed choice of model parameters, the probability of any $d_i$ is proportional to the height of the Gaussian curve directly above that data point, which is shown by the solid lines.
           %
           Adapted from \cite{Gregory2010}.}
  \label{fig:2nd_degree_like}
\end{figure}



\begin{figure}
  \centering
  \includegraphics[width=0.8\linewidth]{../figs/likelihood_heteroskedastic_8.pdf}
  \caption{Same as Fig. \ref{fig:2nd_degree_like}\, but for data with error-bars.}
  \label{fig:2nd_degree_like_heteroskedastic}
\end{figure}


Hopefully these figures shed some light on the ``distribution for data'' interpretation of the likelihood.
But why is it a function of the parameters?

Consider now Fig. \ref{fig:like_two_functions}, which shows what happens when the parameters $A_1, A_2, A_3$ change.
The left panel is as before. In the right panel, note how the probabilities of each data point are now smaller.
So their product will also be smaller, and therefore the likelihood of the full dataset is smaller.
\textbf{The first set of parameters has a higher likelihood than the second set of parameters}.



\begin{figure}
  \centering
  \begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[width=\linewidth]{../figs/likelihood_f1.png}
    % \caption{A subfigure}
    \label{fig:sub1}
  \end{subfigure}%
  \begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[width=\linewidth]{../figs/likelihood_f3.png}
    % \caption{A subfigure}
    \label{fig:sub2}
  \end{subfigure}
  \caption{Same as Fig. \ref{fig:2nd_degree_like_heteroskedastic}, but with two different values for the parameters $A_1, A_2, A_3$.
           The data is the same as before but the model prediction and therefore the means of the Gaussian distributions, have changed. }
  \label{fig:like_two_functions}
\end{figure}



\subsubsection{An example} % (fold)
\label{ssub:an_example}

  We now want to write a \texttt{Python} code to calculate the likelihood in the same exoplanet example.
  As before, we start by stating some of the information that is included in $\mathcal{I}$.
  A typical radial-velocity dataset contains $N$ observations $(t_i, v_i, \sigma_i)$ 
  corresponding to the radial-velocity $v_i$ and its associated uncertainty $\sigma_i$ observed at time $t_i$.

  We also know that the radial-velocity signal as a function of time $t$, produced by an orbiting planet 
  is given by a Keplerian function 
  \[\text{kep}(t,P,K,e,\omega,\chi)\]

  \noindent This is our \emph{model}.
  We will assume that the likelihood is Gaussian

  \begin{equation}
    p(v_i|t_i,\sigma_i, P,K,e,\omega,\chi, \mathcal{I}) \sim \mathcal{N}(\text{kep}(t_i,P,K,e,\omega,\chi), \sigma_i)
  \end{equation}
  %
  and that the observations are independent.

  Let's write this in \texttt{Python}, using the distributions from \texttt{Scipy}.
  We want a function \texttt{log\_likelihood(t,v,sigma,P,K,e,w,X)} that returns the value of the logarithm of the likelihood, given the data and values of the parameters.
  \newpage

  %
  \begin{minted}[linenos,
                 numbersep=7pt,
                 gobble=2,
                 frame=lines,
                 framesep=0mm]{python}
    from scipy.stats import norm
    from numpy import sum

    def log_likelihood(t,v,sigma,P,K,e,w,X):
      # t, v and sigma are arrays
      # P, K, e, w, X are floats

      # the function kep calculates the Keplerian signal
      model_rv = kep(t, P, K, e, w, X)

      loglike = sum([norm(loc=rv, scale=s).logpdf(obs_v) 
                     for rv, s, obs_v in zip(model_rv, sigma, v)])

      return loglike
  \end{minted}

% subsubsection an_example (end)


\vskip1em
\begin{bclogo}[logo=\bclampe, couleur=blue!15, couleurBord=black ,couleurBarre=blue!15]{ think about it}
   What would you have to change in the \texttt{log\_likelihood} function in order to use a Student-\emph{t} distribution instead of a Gaussian?
   Would that help? If yes, in which cases and why?
\end{bclogo}



\newpage
\section{MCMC}

Markov chain Monte Carlo (MCMC) is the workhorse of Bayesian statistics.
But how does it work? 
And what does it actually do?
We will write the code for our own MCMC in the practical classes.
If that is enough for you to \emph{understand} it, skip the next section.
But if you want to know \emph{why} it works, carry on reading.

\subsection{Why does MCMC work?}

  \ldots

\subsection{A basic MCMC implementation}

We will only talk about the Metropolis-Hastings algorithm to do MCMC.
It is probably not the simplest, but it is definitely the most often used.

\noindent The following is adapted slightly from Wikipedia:

\begin{quote}
   Let $f(x)$ be a function that is proportional to the desired probability distribution $P(x)$ (a.k.a. the target distribution).

    \textbf{Initialization:}\\
    Choose an arbitrary point $x_0$ to be the first sample, and choose an arbitrary probability density $Q(x|y)$ which suggests a candidate for the next sample value $x$, given the previous sample value $y$. A usual choice is to let $Q(x|y)$ be a Gaussian distribution centered at $y$. The function $Q$ is referred to as the proposal density or jumping distribution.

    \textbf{For each iteration t:}
    \begin{itemize}
      \item Generate a candidate $x'$ for the next sample by picking from the distribution $Q(x'|x_t)$.
      \item Calculate the acceptance ratio $\alpha = f(x')/f(x_t)$. Because $f$ is proportional to $P$, we have that $\alpha = f(x')/f(x_t) = P(x')/P(x_t)$.
      \item If $\alpha \geq 1$, then the candidate is more likely than $x_t$: automatically accept the candidate by setting $x_{t+1} = x'$. \\
      Otherwise, accept the candidate with probability $\alpha$;\\
      if the candidate is rejected, set $x_{t+1} = x_t$, instead.
\end{itemize}
\end{quote}

\noindent Let's see this in \texttt{Python} code


\begin{minted}[linenos,
               numbersep=7pt,
               gobble=2,
               frame=lines,
               framesep=0mm]{python}
  import numpy as np
  from scipy.stats import norm
  
  niter = 500 # number of iterations
  
  # posterior distribution (the distribution we want to sample from)
  p = lambda x: norm.pdf(x)
  
  x = [0.5] # starting point
  
  for step in range(niter):
     d = np.random.randn() # propose a step

     # calculate the ratio of posterior probabilities
     alpha = p(x[-1]+d) / p(x[-1])
  
     if alpha > 1.:
        x.append(x[-1]+d)     # accept the new step
     else:
        u = np.random.uniform()
        if ratio > u:
           x.append(x[-1]+d)  # accept the new step
        else:
           x.append(x[-1])    # reject the new step (stay where we are)
\end{minted}


%----------------------------------------------------------------------------------------
%   BIBLIOGRAPHY
%----------------------------------------------------------------------------------------

\newpage
\bibliographystyle{unsrt}

\bibliography{/home/joao/phd/bib/zotero_library}

%----------------------------------------------------------------------------------------

\end{document}