%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Thin Sectioned Essay
% LaTeX Template
% Version 1.0 (3/8/13)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original Author:
% Nicolas Diaz (nsdiaz@uc.cl) with extensive modifications by:
% Vel (vel@latextemplates.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%   PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[a4paper,11pt]{article}

\usepackage{draftwatermark}
\SetWatermarkText{draft}
% \SetWatermarkScale{5}
\SetWatermarkColor[gray]{0.8}


\usepackage[utf8]{inputenc}
\usepackage[protrusion=true,expansion=true]{microtype} % Better typography
\usepackage{graphicx} % Required for including pictures
\usepackage{wrapfig} % Allows in-line images
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage[tikz]{bclogo}
\usepackage{minted}

% \setsansfont{Calibri}
% \setmonofont{Consolas}



\usepackage{mathpazo} % Use the Palatino font
\usepackage[T1]{fontenc} % Required for accented characters
\linespread{1.05} % Change line spacing here, Palatino benefits from a slight increase by default

\makeatletter
\renewcommand\@biblabel[1]{\textbf{#1.}} % Change the square brackets for each bibliography item from '[1]' to '1.'
\renewcommand{\@listI}{\itemsep=0pt} % Reduce the space between items in the itemize and enumerate environments and the bibliography

\renewcommand{\maketitle}{ % Customize the title - do not edit title and author name here, see the TITLE block below
\begin{flushright} % Right align
{\LARGE\@title} % Increase the font size of the title

\vspace{50pt} % Some vertical space between the title and author name

{\large\@author} % Author name
\\\@date % Date

\vspace{40pt} % Some vertical space between the author block and abstract
\end{flushright}
}


% \makeatletter
\newenvironment{fancyquote}[2][2em]
  {\setlength{\@tempdima}{#1}%
   \def\chapquote@author{#2}%
   \parshape 1 \@tempdima \dimexpr\textwidth-2\@tempdima\relax%
   \itshape}
  {\par\normalfont\hfill--\ \chapquote@author\hspace*{\@tempdima}\par\bigskip}
\makeatother


%----------------------------------------------------------------------------------------
%   TITLE
%----------------------------------------------------------------------------------------

\title{\textbf{Data don't speak for themselves}\\ % Title
a Bayesian course} % Subtitle

\author{\textsc{João P. Faria} % Author
\\{\textit{Institute of Astrophysics and Space Sciences, Porto}}} % Institution

\date{\today} % Date

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle % Print the title section

%----------------------------------------------------------------------------------------
%   ABSTRACT AND KEYWORDS
%----------------------------------------------------------------------------------------

%\renewcommand{\abstractname}{Summary} % Uncomment to change the name of the abstract to something else

\begin{abstract}
Bayesian statistics is rising in popularity in the astrophysical literature. 
It is no longer a debate: ``work in Bayesian statistics now focuses on applications, computations, and models. Philosophical debates [...] are fading to the background'' \cite{Gelman2014}. 
This is happening for two main reasons: faster computers and more complex models. 
In order to keep up, it is important to understand the fundamentals of Bayesian statistics, but it is as important to know how to deal with data analysis applications. 
In this course I want to provide a brief introduction to advanced concepts in Bayesian statistics.
Emphasis will be on \emph{intuition} and \emph{computation}.
No coin tossing, only real applications that relate to our day-to-day problems. 
\end{abstract}

% \hspace*{3,6mm}\textit{Keywords:} lorem , ipsum , dolor , sit amet , lectus % Keywords

\vspace{30pt} % Some vertical space between the abstract and first section

\tableofcontents


\newpage
\begin{center}
  \section*{Before you read}
  
  This document is not finished! \\
  What I have written here is not completely original work: I follow closely, and base the discussion on, many different sources. 
  Because it's not finished, I have not yet made fair attribution to all these sources.\\[0.2in]
  I mean no infringement of copyright and no plagiarism.
\end{center}





%----------------------------------------------------------------------------------------
%   ESSAY BODY
%----------------------------------------------------------------------------------------

\newpage
\section*{A (tiny) primer on philosophy}
\addcontentsline{toc}{section}{A (tiny) primer on philosophy}

While preparing for this course, I asked people what it was they wanted to learn about.
Much to my dismay, no one answered with ``the philosophy of Bayesian statistics''.
Most want to learn about the ``theory'' and ``applications'' (read MCMC).
They want to know how they can \emph{use} Bayesian statistics in their work%
\footnote{I later read \cite{Loredo1994} and realised this is not the case for our institute only.}.

Fair enough. But bypassing phylosophy means making assumptions.
Therefore, I shall introduce here Jaynes' \emph{robot}, an imaginary being whose brain reasons according to certain definite rules \cite{Jaynes2003}.
These rules will simply be stated, not derived and not defended (Sect. \ref{sec:basics}). 
They will be taken as being true. 
Then, everything that follows logically from them, everything the robot does, will be true.

In the words of \cite{Loredo1994}, these rules make Bayesian inference ``more like integration'' in that it provides a ``collection of tools for finding definitive answers to well-posed problems''. 
Posing the problem will require subjective knowledge; solving it will not.


\section{The basics of probability theory}\label{sec:basics}

Here we present the rules of the game, following very closely (too closely!) the presentation in \cite{Hogg2012}.
Using Bayesian statistics to analyse data (some might call it doing probabilistic inference) means working with likelihoods, prior probabilities, posterior probabilities and marginalization of nuisance parameters.
All this will be explained later but the options we have when working with these mathematical objects are strongly constrained by the rules of probability calculus.

\vskip1em
\begin{fancyquote}{Pierre-Simon Laplace}
   On voit, par cet Essai, que la théorie des probabilités n'est, au fond, que le bon sens réduit au calcul;
\end{fancyquote}

If we have a continuous parameter $a$, and a probability distribution function $p(a)$ for%
\footnote{I say \emph{for} instead of \emph{of}, but I promised no philosophy...} $a$, it must obey the normalization condition
%
\begin{equation}
   1 = \int p(a) \, da
\end{equation}
%
where the integral is limited by the domain%
% \footnote{The domain of $a$ is called the \emph{support} of $p(a)$.}%
~of $a$.

Often times we will have more than one parameter. 
Even if we \emph{condition} $p(a)$ on some particular value of another parameter $b$, that is, we ask for $p(a | b)$ (read ``the pdf for $a$ given $b$''), it must obey the same normalization
%
\begin{equation}\label{eq:normalisation}
   1 = \int p(a|b) \, da
\end{equation}
%

If we have a probability distribution for two things, $p(a,b)$ (read ``the pdf for $a$ and
$b$''), you can always factorize it into two distributions, one for $a$, and one for $b$ given $a$ or the other way around:
%
\begin{align}
   p(a,b) &= p(a) \, p(b|a)\\
   p(a,b) &= p(b) \, p(a|b)
\end{align}
%

These two factorisations together lead%
\footnote{Bayes' theorem is a consequence of the previous equations, it is not assumed as a rule. That's why it's called a theorem, actually.} to Bayes' theorem:
%
\begin{equation}
   p(a|b) = \frac{p(b|a)\,p(a)}{p(b)} .
\end{equation}
%

Conditional probabilities factor just the same as unconditional ones
%
\begin{align}
   p(a,b|c) &= p(a|c) \, p(b|a,c)\\
   p(a,b|c) &= p(b|c) \, p(a|b,c)\\
   p(a|b,c) &= \frac{p(b|a,c)\,p(a|c)}{p(b|c)} \label{eq:bayes}
\end{align}
%   
where we just carried the condition $c$ through all the terms.

You can integrate out or \emph{marginalize} variables you want to get rid of (or \emph{not} infer) by integrals like
%
\begin{align}
   p(a|c) &= \int p(a,b|c) \, db \\
   p(a|c) &= \int p(a|b,c)\,p(b|c) \, db
\end{align}
%
where the second is a factorized version of the first.
Remember that, since $b$ can be a very high-dimensional mathematical object (a set of parameters), integrals like these can be extremely difficult to calculate in practice.


\subsection{Some familiarity}

Let us write some of the preceding equations with more familiar terms%
\footnote{Only if you have heard about Bayesian statistics, otherwise just different terms.}.

\noindent We have data $D$ and a set of parameters $\theta$ that we are interested in learning about. 
In all our analyses we condition on information $\mathcal{I}$ that we have about the world.
Then we can write Eq. \eqref{eq:bayes} as
%
\begin{equation}\label{eq:bayes2}
  p(\theta|D,\mathcal{I}) = \frac{p(\theta|\mathcal{I}) \, p(D|\theta,\mathcal{I})}{p(D|\mathcal{I})}
\end{equation}

The terms in this equation are usually called
%
\begin{itemize}
   \item[] $p(\theta|D,\mathcal{I})$ the posterior distribution
   \item[] $p(\theta|\mathcal{I})$ the prior distribution
   \item[] $p(D|\theta,\mathcal{I})$ the likelihood
   \item[] $p(D|\mathcal{I})$ the evidence, sometimes denoted with a $\mathcal{Z}$.
\end{itemize}
%
but calling them this may hide something important (see Section \ref{sec:likelihood}).

From Eq. \eqref{eq:normalisation} we can derive%
\footnote{Multiply both sides of Eq. \eqref{eq:bayes} by $p(D|\mathcal{I})$ and integrate over $\theta$, noting that $p(D|\mathcal{I})$ does not depend on $\theta$ and that the posterior obeys Eq. \eqref{eq:normalisation}.}
that
%
\begin{equation}
   p(D|\mathcal{I}) = \mathcal{Z} = \int p(\theta|\mathcal{I}) \, p(D|\theta,\mathcal{I}) \, d\theta
\end{equation}
%

Because $\mathcal{Z}$ does not depend on $\theta$, you might see many times Eq. \eqref{eq:bayes2} written as
%
\begin{equation}\label{eq:propto}
   p(\theta|D,\mathcal{I}) \propto p(\theta|\mathcal{I}) \, p(D|\theta,\mathcal{I}) ,
\end{equation}
%
so \textbf{the posterior is proportional to the likelihood times the prior}.
Nevertheless, try to stick with Eq. \eqref{eq:bayes2}; $\mathcal{Z}$ contains in it a big deal of information.

\vskip1em
\begin{bclogo}[logo=\bclampe, couleur=blue!15, couleurBord=black ,couleurBarre=blue!15]{ think about it}
   Eq. \eqref{eq:propto} means that the likelihood and the prior can be defined up to an arbitrary multiplicative constant (i.e. not a function of $\theta$).
\end{bclogo}


For example, imagine we are interested in comparing two models $M_1$ and $M_2$ which have parameters $\theta_1$ and $\theta_2$, respectively. We still only have data $D$. Bayes' theorem works the same:
%
\begin{equation}
   p(M_i|D,\mathcal{I}) = \frac{p(M_i|\mathcal{I}) \, p(D|M_i,\mathcal{I})}{p(D|\mathcal{I})}
\end{equation}
%
and the ratio of model probabilities is
%
\begin{align}
 \frac{p(M_1|D,\mathcal{I})}{p(M_2|D,\mathcal{I})}
   &= \frac{p(M_1|\mathcal{I}) \, p(D|M_1,\mathcal{I})}{p(M_2|\mathcal{I}) \, p(D|M_2,\mathcal{I})} \\[0.4em]
   &= \frac{p(M_1|\mathcal{I}) \, \int p(D,\theta_1|M_1,\mathcal{I})\,d\theta_1}
           {p(M_2|\mathcal{I}) \, \int p(D,\theta_2|M_2,\mathcal{I})\,d\theta_2} \\[0.4em]
   &= \frac{p(M_1|\mathcal{I}) \, \int p(\theta_1|M_1, \mathcal{I}) \, p(D|\theta_1,M_1,\mathcal{I}) \, d\theta_1}
           {p(M_2|\mathcal{I}) \, \int p(\theta_2|M_2, \mathcal{I}) \, p(D|\theta_2,M_2,\mathcal{I}) \, d\theta_2}
           \label{eq:model_comp3} \quad.
\end{align}
%
See how the evidence (of both models) turns out to be important! 

\noindent The term
%
\[\frac{p(M_1|\mathcal{I})}{p(M_2|\mathcal{I})}\]
%
is the ratio of prior probabilities for the two models. 
If we believe they are equally likely at the start, then this is equal to 1.

\vskip1em
\begin{bclogo}[logo=\bclampe, couleur=blue!15, couleurBord=black ,couleurBarre=blue!15]{ think about it}
   $\theta_1$ and $\theta_2$ can be any set of parameters and, in particular, they can have different sizes.
   Say model $M_1$ has 2 parameters $\theta_1 = (a, b)$ and model $M_2$ only has one parameter $\theta_2 = (c)$.
   Then the integrals in Eq. \eqref{eq:model_comp3} are of different dimensionality.
   That's fine, probability theory doesn't care.
   Enough of that ``divide by the degrees of freedom'' nonsense! \cite{Andrae2010}
\end{bclogo}


\section{Assigning probabilities}

Now that we have a set of rules with which we can manipulate our distributions, it is useful to learn how we can assign values to all these terms and actually start calculating things.

\subsection{The prior}\label{sec:prior}

The dreadful prior, we wish we didn't have to deal with it. 
But having to specify priors is a good excuse to learn about different probability distributions. 
See Fig. \ref{fig:distributions}, which shows the general form of many continuous probability distributions.

We can start with the Normal distribution.
A variable $x$ is normally distributed if its pdf is

\begin{equation}
  \text{pdf}(x|\mu, \sigma) = \frac{1}{\sigma \sqrt{2\pi}} 
                              \exp\left[-\frac{(x-\mu)^2}{2\sigma^2}\right]
\end{equation}

where $\mu$ and $\sigma$ are the two parameters of the Normal distribution.
We will use the following notation to say that $x$ follows a Normal distribution:
%
\[x \sim \mathcal{N}(\mu, \sigma)\]
%

The Normal distribution is defined on the real line, so $x$ can take any value between $-\infty$ and $\infty$.
The parameter $\mu$ is the mean of the distribution and $\sigma$ is the standard deviation.
Values of $x$ closer to $\mu$ are more probable that those far from $\mu$.


The uniform distribution is also quite common
%
\[x \sim \mathcal{U}(a, b) \quad \text{if} \quad \text{pdf}(x|a,b) = \frac{1}{a-b} \]
%

For the uniform distribution, all values between $a$ and $b$ are equally probable.
The probability that $x<a$ is 0 and the same for $x>b$. These values of $x$ are \emph{impossible}.


Let us introduce briefly one more distribution, the \emph{t}-distribution:
%
\begin{equation}
  x \sim t(\nu,\mu,\sigma) \quad \text{if} \quad \text{pdf}(x|\nu, \mu, \sigma) = 
            \frac{\Gamma(\frac{\nu+1}{2})}{\Gamma(\frac{\nu}{2})\sqrt{\pi\nu}\,\sigma}
            \left[ 1 + \frac{1}{\nu} \left(\frac{x-\mu}{\sigma}\right)^2 \right]
                  ^{-\frac{\nu+1}{2}}
\label{eq:tdistribution}
\end{equation}
%
with the degrees of freedom $\nu$, the mean $\mu$ and the scale $\sigma$ as parameters.
In Eq. \eqref{eq:tdistribution}, $\Gamma$ is the gamma function.

This distribution looks complicated but I mention it here for one reason: note how in Fig. \ref{fig:distributions}, the normal and \emph{t} distributions look very similar, they are both bell-shaped.
The distinguishing feature is that the \emph{t}-distribution has \emph{heavier tails}, that is, values of $x$ far from the mean are more probable if $x$ is \emph{t} distributed than if $x$ if normally distributed.
How heavy the tails are depends on the parameter $\nu$.
For example, imagine that
%
\begin{align}
  x_1 & \sim \mathcal{N}(0, 1) \\
  x_2 & \sim t(2, 0, 1)
\end{align}
%
and you obtain 100\,000 random samples from these two distributions. 
Then you calculate the minimum value of all the samples for $x_1$ and all the samples for $x_2$.
Will these values be very different?
%
\begin{minted}[linenos,
               numbersep=7pt,
               gobble=2,
               frame=lines,
               framesep=0mm]{python}
  from scipy.stats import norm, t
  
  print min( t(1., loc=0, scale=1).rvs(100000) )
  print min( norm(loc=0, scale=1).rvs(100000) )
\end{minted}

They are completely different! By orders of magnitude!

\noindent The \emph{t}-distribution allows for more extreme values.
This will come in handy when we deal with outliers.

\vskip1em
Other distributions have different pdfs and different parameters. 
Wikipedia usually has a lot of information about the most common ones, just search for the names you see in Fig. \ref{fig:distributions}. 

\begin{figure}[h]
  \centering
  \includegraphics[width=0.7\linewidth]{../figs/distributions.png}
  \caption{Continuous probability distributions. Adapted from \href{http://semanticommunity.info/Data_Science/Doing_Data_Science\#Slide_1_Hubway_Data_Visualization_Challenge:_Spotfire}{here}.}
  \label{fig:distributions}
\end{figure}


The key concept about priors is to use (some of) these probability distributions to describe our beliefs about the parameters in our models.

\begin{itemize}
  \item if any value of the parameter seems equally likely but you have an idea of its order of magnitude, try a uniform distribution in a sensible range.
  \item if one value is somewhat more likely and, again, you know the order of magnitude, try a normal distribution centred in that value.
  \item if any value is equally likely within a few orders of magnitude, use a log-normal or an exponential distribution. [check!!!]
  \item if the parameter takes values between 0 and 1, the beta distribution is defined in this interval and can take a wide range of forms, depending on its parameters.
\end{itemize}

Every time you come up with a prior, you are using your expert knowledge about the problem.
Don't underestimate this knowledge by trying to set an ``uninformative'' prior at all costs.
If you are not sure, try a few different priors and see if the results make sense and are consistent. 

The only way in which you can go completely wrong and change the results dramatically is by setting the prior to 0. No amount of data can change a prior which is zero.



% Finally, if a result is not robust to reasonable changes in the problem specification, this itself should be recognized as important information.  If the answer depends sensitively on something we do not know, then we do not know the answer



\subsection{The likelihood}\label{sec:likelihood}

The likelihood is a prior.
I will repeat so you know this is not a typo: the likelihood is a prior.
The term $p(D|\theta,I)$ represents your beliefs on what the data will be like, given parameters $\theta$ and information $I$.
Therefore, the likelihood encodes prior information.
%
Following \cite{Brewer2013}, the likelihood is \emph{not} 
\begin{itemize}
   \item[-] the process that generated the data
   \item[-] the pdf that your data kind of looks like when you plot it in a histogram
\end{itemize}

It is, instead, what we usually call \emph{the model}.
And the model is nothing else than a set of assumptions about the data and how they relate to the parameters.
\textbf{The likelihood provides a (\emph{the}) connection from $\theta$ to $D$}.

% But now comes the part which, conceptually, is harder to understand. 
% When we write $p(D|\theta,I)$, this is a distribution for the data, given some values for the parameters $\theta$.
% A ``point'' taken randomly from $p(D|\theta,I)$, corresponds to a random dataset.
% But the likelihood is sometimes seen instead as a function of the parameters, given the observed dataset. 
% In this form, the symbol $\mathcal{L}(\theta)$ is often used.

% \begin{itemize}
%   \item $p(D|\theta,I)$ - distribution for datasets, given $\theta$
%   \item $\mathcal{L}(\theta)$ - function of 
% \end{itemize}



\section{MCMC}

Markov chain Monte Carlo (MCMC) is the workhorse of Bayesian statistics.
But how does it work? 
And what does it actually do?
We will write the code for our own MCMC in the practical classes.
If that is enough for you to \emph{understand} it, skip the next section.
But if you want to know \emph{why} it works, carry on reading.


\subsection{A basic MCMC implementation}

We will only talk about the Metropolis-Hastings algorithm to do MCMC.
It is probably not the simplest, but it is definitely the most often used.

\noindent The following is adapted slightly from Wikipedia:

\begin{quote}
   Let $f(x)$ be a function that is proportional to the desired probability distribution $P(x)$ (a.k.a. the target distribution).

    \textbf{Initialization:}\\
    Choose an arbitrary point $x_0$ to be the first sample, and choose an arbitrary probability density $Q(x|y)$ which suggests a candidate for the next sample value $x$, given the previous sample value $y$. A usual choice is to let $Q(x|y)$ be a Gaussian distribution centered at $y$. The function $Q$ is referred to as the proposal density or jumping distribution.

    \textbf{For each iteration t:}
    \begin{itemize}
      \item Generate a candidate $x'$ for the next sample by picking from the distribution $Q(x'|x_t)$.
      \item Calculate the acceptance ratio $\alpha = f(x')/f(x_t)$. Because $f$ is proportional to $P$, we have that $\alpha = f(x')/f(x_t) = P(x')/P(x_t)$.
      \item If $\alpha \geq 1$, then the candidate is more likely than $x_t$: automatically accept the candidate by setting $x_{t+1} = x'$. \\
      Otherwise, accept the candidate with probability $\alpha$;\\
      if the candidate is rejected, set $x_{t+1} = x_t$, instead.
\end{itemize}
\end{quote}

\noindent Let's see this in \texttt{Python} code


\begin{minted}[linenos,
               numbersep=7pt,
               gobble=2,
               frame=lines,
               framesep=0mm]{python}
  import numpy as np
  from scipy.stats import norm
  
  niter = 500 # number of iterations
  
  # posterior distribution (the distribution we want to sample from)
  p = lambda x: norm.pdf(x)
  
  x = [0.5] # starting point
  
  for step in range(niter):
     d = np.random.randn() # propose a step

     # calculate the ratio of posterior probabilities
     alpha = p(x[-1]+d) / p(x[-1])
  
     if alpha > 1.:
        x.append(x[-1]+d)     # accept the new step
     else:
        u = np.random.uniform()
        if ratio > u:
           x.append(x[-1]+d)  # accept the new step
        else:
           x.append(x[-1])    # reject the new step (stay where we are)
\end{minted}


%----------------------------------------------------------------------------------------
%   BIBLIOGRAPHY
%----------------------------------------------------------------------------------------

\newpage
\bibliographystyle{unsrt}

\bibliography{/home/joao/phd/bib/zotero_library}

%----------------------------------------------------------------------------------------

\end{document}